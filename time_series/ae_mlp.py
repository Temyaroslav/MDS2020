import gc
import numpy as np
import pandas as pd

import tensorflow as tf
from keras.callbacks import ModelCheckpoint, EarlyStopping

from splitting import PurgedGroupTimeSeriesSplit


tf.random.set_seed(42)

print('Loading...')
train = pd.read_parquet(r'C:\Users\Yaroslav\Downloads\jane_street_train.parquet')
features = [c for c in train.columns if 'feature' in c]

print('Filling...')
train = train.query('date > 85').reset_index(drop = True)
train = train.query('weight > 0').reset_index(drop = True)
train[features] = train[features].fillna(method = 'ffill').fillna(0)
train['action'] = ((train['resp_1'] > 0) & (train['resp_2'] > 0) & (train['resp_3'] > 0) & (train['resp_4'] > 0) & (train['resp'] > 0)).astype('int')

resp_cols = ['resp', 'resp_1', 'resp_2', 'resp_3', 'resp_4']

X = train[features].values
y = np.stack([(train[c] > 0).astype('int') for c in resp_cols]).T
date = train['date'].values
weight = train['weight'].values
resp = train['resp'].values
sw = np.mean(np.abs(train[resp_cols].values), axis = 1)

n_splits = 5
group_gap = 31


def weighted_average(a):
    w = []
    n = len(a)
    for j in range(1, n + 1):
        j = 2 if j == 1 else j
        w.append(1 / (2**(n + 1 - j)))
    return np.average(a, weights = w)


def create_ae_mlp(num_columns, num_labels, hidden_units, dropout_rates, ls=1e-2, lr=1e-3):
    inp = tf.keras.layers.Input(shape=(num_columns,))
    x0 = tf.keras.layers.BatchNormalization()(inp)

    encoder = tf.keras.layers.GaussianNoise(dropout_rates[0])(x0)
    encoder = tf.keras.layers.Dense(hidden_units[0])(encoder)
    encoder = tf.keras.layers.BatchNormalization()(encoder)
    encoder = tf.keras.layers.Activation('swish')(encoder)

    decoder = tf.keras.layers.Dropout(dropout_rates[1])(encoder)
    decoder = tf.keras.layers.Dense(num_columns, name='decoder')(decoder)

    x_ae = tf.keras.layers.Dense(hidden_units[1])(decoder)
    x_ae = tf.keras.layers.BatchNormalization()(x_ae)
    x_ae = tf.keras.layers.Activation('swish')(x_ae)
    x_ae = tf.keras.layers.Dropout(dropout_rates[2])(x_ae)

    out_ae = tf.keras.layers.Dense(num_labels, activation='sigmoid', name='ae_action')(x_ae)

    x = tf.keras.layers.Concatenate()([x0, encoder])
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.Dropout(dropout_rates[3])(x)

    for i in range(2, len(hidden_units)):
        x = tf.keras.layers.Dense(hidden_units[i])(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.Activation('swish')(x)
        x = tf.keras.layers.Dropout(dropout_rates[i + 2])(x)

    out = tf.keras.layers.Dense(num_labels, activation='sigmoid', name='action')(x)

    model = tf.keras.models.Model(inputs=inp, outputs=[decoder, out_ae, out])
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),
                  loss={'decoder': tf.keras.losses.MeanSquaredError(),
                        'ae_action': tf.keras.losses.BinaryCrossentropy(label_smoothing=ls),
                        'action': tf.keras.losses.BinaryCrossentropy(label_smoothing=ls),
                        },
                  metrics={'decoder': tf.keras.metrics.MeanAbsoluteError(name='MAE'),
                           'ae_action': tf.keras.metrics.AUC(name='AUC'),
                           'action': tf.keras.metrics.AUC(name='AUC'),
                           },
                  )

    return model


params = {'num_columns': len(features),
          'num_labels': 5,
          'hidden_units': [96, 96, 896, 448, 448, 256],
          'dropout_rates': [0.03527936123679956, 0.038424974585075086, 0.42409238408801436, 0.10431484318345882, 0.49230389137187497, 0.32024444956111164, 0.2716856145683449, 0.4379233941604448],
          'ls': 0,
          'lr':1e-3,
         }

scores = []
batch_size = 4096
gkf = PurgedGroupTimeSeriesSplit(n_splits=n_splits, group_gap=group_gap)
for fold, (tr, te) in enumerate(gkf.split(train['action'].values, train['action'].values, train['date'].values)):
    ckp_path = f'JSModel_{fold}.hdf5'
    model = create_ae_mlp(**params)
    ckp = ModelCheckpoint(ckp_path, monitor='val_action_AUC', verbose=0,
                          save_best_only=True, save_weights_only=True, mode='max')
    es = EarlyStopping(monitor='val_action_AUC', min_delta=1e-4, patience=10, mode='max',
                       baseline=None, restore_best_weights=True, verbose=0)
    history = model.fit(X[tr], [X[tr], y[tr], y[tr]], validation_data=(X[te], [X[te], y[te], y[te]]),
                        sample_weight=sw[tr],
                        epochs=100, batch_size=batch_size, callbacks=[ckp, es], verbose=0)
    hist = pd.DataFrame(history.history)
    score = hist['val_action_AUC'].max()
    print(f'Fold {fold} ROC AUC:\t', score)
    scores.append(score)

    # K.clear_session()
    del model
    rubbish = gc.collect()

print('Weighted Average CV Score:', weighted_average(scores))