{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Part 1. `scikit-learn`  basics\n",
    "\n",
    "[`sklearn`](https://scikit-learn.org/stable/getting_started.html) is a very popular Python library, where plenly of usefull machine learning tools (models, preprocessing methods, etc.) are implemented. \n",
    "\n",
    "We will consider three usefull building-blocks of sklearn:\n",
    "- Estimators \n",
    "- Transformers \n",
    "- Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Estimators\n",
    "\n",
    "Models, aka estimators, are objects which perform model estimation. They have 2 main methods:\n",
    "\n",
    "* Method `fit()`:\n",
    "    - takes as input design matrix `X` and target values `y`\n",
    "    - `X` is supposed to have the shape `(n_samples, n_features)`\n",
    "    - for unsupervised models `y=None` by default\n",
    "    - trains the model (aka finds optimal parameters)\n",
    "    \n",
    "* Method `predict()`:\n",
    "    - takes as input design matrix `X`\n",
    "    - returns predicted target values\n",
    "    - makes sense to use it **after** the `fit()`\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3) (2,)\n",
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "#Consider toy dataset\n",
    "X = np.array([[ 1,  2,  3], [11, 12, 13]])\n",
    "y = np.array([2.1, 11.9])\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "X_test =  np.array([[ 2, 3, 4]])\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LinearRegression()` - is an example of an estimator. You'll find out more about this model next week.\n",
    "\n",
    "\n",
    "Fit linear regression and predict target variable for the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.08])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Init the model and set all the hyperparameters (if there are any)\n",
    "lr = LinearRegression()\n",
    "# Train the model\n",
    "lr.fit(X, y)\n",
    "\n",
    "# make a prediction\n",
    "lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Transformers\n",
    "\n",
    "Objects, which are mostly used to pre-process and transform the data. It's interface is very similar to estimators, but they have method `transform` instead of `predict`.\n",
    "\n",
    "     \n",
    "Most sklearn transformers can be found in the following modules:\n",
    "- [sklearn.impute](https://scikit-learn.org/stable/modules/impute.html#impute) --- missing values imputation\n",
    "- [sklearn.preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing) --- scaling, centering, normalization and binarization\n",
    "\n",
    "We will discuss some of them in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the design matrix `X` usign `StandardScaler`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3]\n",
      " [11 12 13]]\n",
      "[[-1. -1. -1.]\n",
      " [ 1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Init, fit and transform\n",
    "sc = StandardScaler()\n",
    "\n",
    "sc.fit(X)\n",
    "print(X)\n",
    "      \n",
    "X_transformed = sc.transform(X)\n",
    "print(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1., -1.],\n",
       "       [ 1.,  1.,  1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the same, but in 1 line\n",
    "sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pipelines\n",
    "\n",
    "\n",
    " Usually, we have to apply several transformers to our dataset (e.g. fill in missing values, standartize all the numerical features) before we can train the model:\n",
    "\n",
    "<img src=\"1_ML_pipe.png\" width=600 height=600 />\n",
    "\n",
    "Recall, that each block here requires calling `fit` and `transorm`/`predict` methods to get an output. \n",
    "\n",
    "`Pipeline` allows us to combine transformers in estimators in one class, so that we can call only one `fit` to train 'em all!\n",
    "<img src=\"2_ML_pipe.png\" width=600 height=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following setting:\n",
    "\n",
    "1. Use Standard Scaler\n",
    "2. Fit linear regression model\n",
    "3. Make prediction on `X_test`\n",
    "\n",
    "With the `Pipeline`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.08])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "# create a pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('regression', LinearRegression())\n",
    "])\n",
    "\n",
    "# fit the whole pipeline\n",
    "pipe.fit(X, y)\n",
    "\n",
    "# we can now use it like any other estimator and make a prediction\n",
    "pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is much more in `sklearn`, you can read about all the classes and function in the [user guide](https://scikit-learn.org/stable/user_guide.html#user-guide)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "X = [['Male', 1], ['Female', 10], ['Female', 2]]\n",
    "enc.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.Dataf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
